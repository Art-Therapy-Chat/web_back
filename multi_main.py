from dotenv import load_dotenv
load_dotenv()
from embeddings import vectorstore           # ë²¡í„° DB
from rag_engine import AdvancedConversationalRAG  # ë©€í‹°ì¿¼ë¦¬ RAG ì—”ì§„

from fastapi import FastAPI
from pydantic import BaseModel
from caption import generate_caption
from model import generate_with_qwen
from fastapi.middleware.cors import CORSMiddleware
import logging
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI()
# CORS ì„¤ì • - ë” ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì¶œì²˜ í—ˆìš©
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)

# -------------------------------------
# RAG ì—”ì§„ ì´ˆê¸°í™”
# -------------------------------------
rag = AdvancedConversationalRAG(vectorstore)

# ----------------------------- #
# 1) ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
# ----------------------------- #
class CaptionRequest(BaseModel):
    image_base64: str

@app.post("/caption")
def caption(req: CaptionRequest):
    logger.info("=" * 80)
    logger.info("ğŸ“¸ [CAPTION] ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: Florence-2-large")
    logger.info(f"ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {len(req.image_base64)} bytes")
    
    caption = generate_caption(req.image_base64)
    
    logger.info(f"âœ… [CAPTION] ìƒì„±ëœ ìº¡ì…˜: {caption}")
    logger.info("=" * 80)
    return {"caption": caption}

# ----------------------------- #
# 2) ë©€í‹°ì¿¼ë¦¬ ê¸°ë°˜ RAG ê²€ìƒ‰
# ----------------------------- #
class RagRequest(BaseModel):
    caption: str
    image_type: str    # "ì§‘" | "ë‚˜ë¬´" | "ì‚¬ëŒ"

@app.post("/rag")
def rag_search_api(req: RagRequest):
    logger.info("=" * 80)
    logger.info("ğŸ” [RAG] RAG ê²€ìƒ‰ ì‹œì‘ (ê²€ìƒ‰ ì „ìš© ëª¨ë“œ)")
    logger.info("ğŸ¤– ì¿¼ë¦¬ ì¬ì‘ì„± ëª¨ë¸: GPT-4o (OpenAI)")
    logger.info(f"ì…ë ¥ ìº¡ì…˜: {req.caption}")
    logger.info(f"ì´ë¯¸ì§€ íƒ€ì…: {req.image_type}")
    
    try:
        # search_only ë©”ì„œë“œ ì‚¬ìš© (í•´ì„ ìƒì„± ì œê±°)
        result = rag.search_only(req.caption, req.image_type)
        
        logger.info(f"âœ… [RAG] ê²€ìƒ‰ ì™„ë£Œ")
        logger.info(f"ì¬ì‘ì„±ëœ ì¿¼ë¦¬: {result.get('rewritten_queries', [])}")
        logger.info(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result.get('rag_docs', []))}")
        
        # ê° ë¬¸ì„œì˜ ë‚´ìš© ì¶œë ¥
        for idx, doc in enumerate(result.get('rag_docs', []), 1):
            logger.info(f"\nğŸ“„ ë¬¸ì„œ {idx}:")
            logger.info(f"  ë‚´ìš©: {doc[:200]}..." if len(doc) > 200 else f"  ë‚´ìš©: {doc}")
        
        logger.info("=" * 80)
        return result
        
    except Exception as e:
        logger.error(f"âŒ [RAG] ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        import traceback
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        logger.info("=" * 80)
        
        # ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ì—ëŸ¬ ë°œìƒ ì‹œ)
        return {
            "rewritten_queries": [req.caption],
            "rag_docs": [],
            "error": str(e)
        }

# ----------------------------- #
# 3) Qwen ë¡œë¼ ëª¨ë¸ ê°œë³„ í•´ì„
# ----------------------------- #
class InterpretSingle(BaseModel):
    caption: str
    rag_docs: list
    image_type: str

@app.post("/interpret_single")
def interpret_single(req: InterpretSingle):
    logger.info("=" * 80)
    logger.info("ğŸ§  [INTERPRET_SINGLE] ê°œë³„ í•´ì„ ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: Qwen (helena29/Qwen2.5_LoRA_for_HTP)")
    logger.info(f"ì´ë¯¸ì§€ íƒ€ì…: {req.image_type}")
    logger.info(f"ì…ë ¥ ìº¡ì…˜: {req.caption}")
    logger.info(f"RAG ë¬¸ì„œ ìˆ˜: {len(req.rag_docs)}")
    
    # RAG ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì°¸ê³ ë¬¸í—Œìœ¼ë¡œ í™œìš©, ì—†ìœ¼ë©´ ìº¡ì…˜ë§Œìœ¼ë¡œ í•´ì„
    if req.rag_docs and len(req.rag_docs) > 0:
        literature_section = f"""
        HTP Research References (Korean):
        {req.rag_docs}
        
        Please refer to the above literature for your interpretation.
        """
        logger.info("âœ… RAG ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ í•´ì„")
    else:
        literature_section = """
        No specific references available. Please base your interpretation on general HTP psychology principles and the observed drawing features from the caption.
        """
        logger.info("âš ï¸  RAG ë¬¸ì„œ ì—†ìŒ - ì¼ë°˜ì ì¸ HTP ì›ë¦¬ë¡œ í•´ì„")
    
    prompt = f"""
        You are an expert in HTP (House-Tree-Person) psychological test interpretation.

**Input Data:**
* **Drawing Type:** {req.image_type}
* **Drawing Caption:** {req.caption}
* **Reference Literature:** {literature_section}

**Task:**
Analyze the provided Drawing Caption and generate a psychological interpretation. Instead of writing a general essay, you must break down the caption into specific visual features and interpret each one individually based on HTP research patterns and psychological theory.

**Output Structure:**

**Part 1: Feature-by-Feature Analysis**
Extract key visual elements from the caption and provide a specific interpretation for each. Use the following format for every distinct feature found in the caption:

* **Visual Feature:** [Quote the specific part of the caption, e.g., "The tree is large"]
    * **Interpretation:** [Explain what this specific feature indicates psychologically. Refer to the provided literature if applicable. e.g., "This suggests a strong ego or high energy level..."]

**Part 2: Comprehensive Synthesis**
Provide a brief summary (1-2 paragraphs) integrating the features analyzed above. Discuss the individual's potential emotional state, social orientation, and coping strategies as a whole.

**Important Guidelines:**
* Ensure every visual detail mentioned in the caption (e.g., placement, size, specific objects like stars or flowers) is analyzed in Part 1.
* Use professional psychological terminology.
* Maintain a professional, analytical, and empathetic tone.
* **Write the response in English.**
    """
    
    logger.info(f"\nğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} characters")

    result = generate_with_qwen(prompt)
    
    logger.info(f"âœ… [INTERPRET_SINGLE] í•´ì„ ì™„ë£Œ")
    logger.info(f"ìƒì„±ëœ í•´ì„: {result}")
    logger.info("=" * 80)
    return {"interpretation": result}

# ----------------------------- #
# 4) GPT ë²ˆì—­ API
# ----------------------------- #
from openai import OpenAI
client = OpenAI()

class TranslateRequest(BaseModel):
    text: str

@app.post("/translate")
def translate(req: TranslateRequest):
    """ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
    logger.info("ğŸŒ [TRANSLATE] ë²ˆì—­ ì‹œì‘")
    logger.info(f"ì›ë¬¸ (ì˜ì–´): {req.text[:100]}...")
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a professional translator. Translate the given English text to natural Korean. Only provide the translation, nothing else."},
                {"role": "user", "content": req.text}
            ],
            temperature=0.3
        )
        
        translated = response.choices[0].message.content
        logger.info(f"ë²ˆì—­ ê²°ê³¼ (í•œêµ­ì–´): {translated[:100]}...")
        return {"translated": translated}
        
    except Exception as e:
        logger.error(f"âŒ [TRANSLATE] ë²ˆì—­ ì‹¤íŒ¨: {str(e)}")
        return {"translated": req.text}  # ì‹¤íŒ¨ì‹œ ì›ë¬¸ ë°˜í™˜

# ----------------------------- #
# 5) Qwen ëª¨ë¸ë¡œ ì¶”ê°€ ì§ˆë¬¸ ìƒì„± (ì˜ì–´)
# ----------------------------- #

class QuestionReq(BaseModel):
    conversation: list

@app.post("/questions")
def questions(req: QuestionReq):
    logger.info("=" * 80)
    logger.info("â“ [QUESTIONS] ì¶”ê°€ ì§ˆë¬¸ ìƒì„± ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: Qwen (helena29/Qwen2.5_LoRA_for_HTP)")
    logger.info(f"ëŒ€í™” ê¸°ë¡ ìˆ˜: {len(req.conversation)}")
    
    for idx, msg in enumerate(req.conversation[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ ë¡œê¹…
        logger.info(f"  ë©”ì‹œì§€ {idx}: {msg.get('role')} - {msg.get('content')[:100]}...")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
    conversation_text = "\n".join([
        f"{msg.get('role').upper()}: {msg.get('content')}" 
        for msg in req.conversation
    ])
    
    prompt = f"""
You are a professional psychologist conducting an HTP (House-Tree-Person) psychological assessment interview.

Conversation History:
{conversation_text}

Based on the conversation above, generate ONE follow-up question in English to gather more psychological insights.

Important Guidelines:
- Your response must be a single question in English only.
- The question should help understand the person's psychological state better.
- Keep the question clear, professional, and focused.
- Do not include any explanations, just the question itself.
"""
    
    result = generate_with_qwen(prompt)
    
    logger.info(f"âœ… [QUESTIONS] ìƒì„±ëœ ì§ˆë¬¸: {result}")
    logger.info("=" * 80)
    return {"question": result}

# ----------------------------- #
# 6) ìµœì¢… í•´ì„ (GPT-4o)
# ----------------------------- #
class InterpretFinal(BaseModel):
    single_results: dict
    conversation: list

@app.post("/interpret_final")
def interpret_final(req: InterpretFinal):
    logger.info("=" * 80)
    logger.info("ğŸ¯ [INTERPRET_FINAL] ìµœì¢… í•´ì„ ìƒì„± ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: GPT-4o (OpenAI)")
    logger.info(f"ì§‘ í•´ì„: {req.single_results.get('house', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ë‚˜ë¬´ í•´ì„: {req.single_results.get('tree', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ì‚¬ëŒ í•´ì„: {req.single_results.get('person', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ëŒ€í™” ê¸°ë¡ ìˆ˜: {len(req.conversation)}")
    
    # GPT ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        {
            "role": "system",
            "content": "You are a professional psychological counselor specializing in HTP (House-Tree-Person) test interpretation. Provide comprehensive, insightful psychological analysis in Korean."
        },
        {
            "role": "user",
            "content": f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ HTP ê²€ì‚¬ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì‹¬ë¦¬ í•´ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì§‘ í•´ì„ (House Interpretation):
{req.single_results.get('house','N/A')}

ë‚˜ë¬´ í•´ì„ (Tree Interpretation):
{req.single_results.get('tree','N/A')}

ì‚¬ëŒ í•´ì„ (Person Interpretation):
{req.single_results.get('person','N/A')}

ì‚¬ìš©ìì™€ ë‚˜ëˆˆ ëŒ€í™”:
{req.conversation}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… HTP ì‹¬ë¦¬ í•´ì„ì„ 5ê°œ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ì¤‘ìš” ì§€ì¹¨:
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ê° ê·¸ë¦¼(ì§‘, ë‚˜ë¬´, ì‚¬ëŒ)ì˜ ê°œë³„ í•´ì„ì„ í†µí•©í•˜ì—¬ ì „ì²´ì ì¸ ì‹¬ë¦¬ ìƒíƒœë¥¼ ë¶„ì„í•˜ì„¸ìš”
- ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë” ê¹Šì´ ìˆëŠ” í•´ì„ì„ ì œê³µí•˜ì„¸ìš”
- ì „ë¬¸ì ì´ê³  ë”°ëœ»í•œ ì–´ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš”
- 5ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”
"""
        }
    ]
    
    logger.info(f"ğŸ“ GPT ìš”ì²­ ì „ì†¡ ì¤‘...")
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7,
        max_tokens=2000
    )
    
    result = response.choices[0].message.content
    
    logger.info(f"âœ… [INTERPRET_FINAL] ìµœì¢… í•´ì„ ì™„ë£Œ")
    logger.info(f"ìƒì„±ëœ ìµœì¢… í•´ì„ (ì²˜ìŒ 200ì): {result[:200]}...")
    logger.info("=" * 80)
    return {"final": result}
