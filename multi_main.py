from dotenv import load_dotenv
load_dotenv()
from embeddings import vectorstore           # ë²¡í„° DB
from rag_engine import AdvancedConversationalRAG  # ë©€í‹°ì¿¼ë¦¬ RAG ì—”ì§„

from fastapi import FastAPI
from pydantic import BaseModel
from caption import generate_caption
from model import generate_with_qwen
from fastapi.middleware.cors import CORSMiddleware
import logging
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI()
# CORS ì„¤ì • - ë” ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì¶œì²˜ í—ˆìš©
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)

# -------------------------------------
# RAG ì—”ì§„ ì´ˆê¸°í™”
# -------------------------------------
rag = AdvancedConversationalRAG(vectorstore)

# ----------------------------- #
# 1) ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
# ----------------------------- #
class CaptionRequest(BaseModel):
    image_base64: str

@app.post("/caption")
def caption(req: CaptionRequest):
    logger.info("=" * 80)
    logger.info("ğŸ“¸ [CAPTION] ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ì‹œì‘")
    logger.info(f"ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {len(req.image_base64)} bytes")
    
    caption = generate_caption(req.image_base64)
    
    logger.info(f"âœ… [CAPTION] ìƒì„±ëœ ìº¡ì…˜: {caption}")
    logger.info("=" * 80)
    return {"caption": caption}

# ----------------------------- #
# 2) ë©€í‹°ì¿¼ë¦¬ ê¸°ë°˜ RAG ê²€ìƒ‰
# ----------------------------- #

# ì˜ì–´â†’í•œêµ­ì–´ ë§¤í•‘
IMAGE_TYPE_MAP = {
    "house": "ì§‘",
    "tree": "ë‚˜ë¬´",
    "person": "ì‚¬ëŒ"
}

class RagRequest(BaseModel):
    caption: str
    image_type: str    # "ì§‘" | "ë‚˜ë¬´" | "ì‚¬ëŒ" ë˜ëŠ” "house" | "tree" | "person"

@app.post("/rag")
def rag_search_api(req: RagRequest):
    logger.info("=" * 80)
    logger.info("ğŸ” [RAG] RAG ê²€ìƒ‰ ì‹œì‘")
    logger.info(f"ì…ë ¥ ìº¡ì…˜: {req.caption}")
    logger.info(f"ì´ë¯¸ì§€ íƒ€ì… (ì›ë³¸): {req.image_type}")
    
    # ì˜ì–´ íƒ€ì…ì´ë©´ í•œêµ­ì–´ë¡œ ë³€í™˜
    image_type_kr = IMAGE_TYPE_MAP.get(req.image_type, req.image_type)
    logger.info(f"ì´ë¯¸ì§€ íƒ€ì… (ë³€í™˜ë¨): {image_type_kr}")
    
    try:
        result = rag.query(req.caption, image_type_kr)
        
        logger.info(f"âœ… [RAG] ê²€ìƒ‰ ì™„ë£Œ")
        logger.info(f"ì¬ì‘ì„±ëœ ì¿¼ë¦¬: {result.get('rewritten_queries', [])}")
        logger.info(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result.get('rag_docs', []))}")
        
        # ê° ë¬¸ì„œì˜ ë‚´ìš© ì¶œë ¥
        for idx, doc in enumerate(result.get('rag_docs', []), 1):
            logger.info(f"\nğŸ“„ ë¬¸ì„œ {idx}:")
            logger.info(f"  ë‚´ìš©: {doc[:200]}..." if len(doc) > 200 else f"  ë‚´ìš©: {doc}")
        
        logger.info("=" * 80)
        return result
        
    except Exception as e:
        logger.error(f"âŒ [RAG] ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        import traceback
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        logger.info("=" * 80)
        
        # ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ì—ëŸ¬ ë°œìƒ ì‹œ)
        return {
            "result": "ê²€ìƒ‰ ì‹¤íŒ¨",
            "rewritten_queries": [req.caption],
            "rag_docs": [],
            "error": str(e)
        }

# ----------------------------- #
# 3) Qwen ë¡œë¼ ëª¨ë¸ ê°œë³„ í•´ì„
# ----------------------------- #
class InterpretSingle(BaseModel):
    caption: str
    rag_docs: list
    image_type: str

@app.post("/interpret_single")
def interpret_single(req: InterpretSingle):
    logger.info("=" * 80)
    logger.info("ğŸ§  [INTERPRET_SINGLE] ê°œë³„ í•´ì„ ì‹œì‘")
    logger.info(f"ì´ë¯¸ì§€ íƒ€ì…: {req.image_type}")
    logger.info(f"ì…ë ¥ ìº¡ì…˜: {req.caption}")
    logger.info(f"RAG ë¬¸ì„œ ìˆ˜: {len(req.rag_docs)}")
    
    # RAG ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì°¸ê³ ë¬¸í—Œìœ¼ë¡œ í™œìš©, ì—†ìœ¼ë©´ ìº¡ì…˜ë§Œìœ¼ë¡œ í•´ì„
    if req.rag_docs and len(req.rag_docs) > 0:
        literature_section = f"""
        Relevant literature from HTP research:
        {req.rag_docs}
        
        Use this literature as reference for your interpretation.
        """
        logger.info("âœ… RAG ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ í•´ì„")
    else:
        literature_section = """
        No specific literature available. Base your interpretation on general HTP psychological principles and the drawing characteristics observed in the caption.
        """
        logger.info("âš ï¸  RAG ë¬¸ì„œ ì—†ìŒ - ì¼ë°˜ì ì¸ HTP ì›ë¦¬ë¡œ í•´ì„")
    
    prompt = f"""
        You are an HTP (House-Tree-Person) psychological interpretation expert.
        
        Drawing type:
        {req.image_type}
        
        Image caption:
        {req.caption}
        
        {literature_section}
        
        Write an HTP interpretation in exactly 3â€“5 sentences based on the drawing characteristics.
        
        IMPORTANT INSTRUCTIONS:
        - Your ENTIRE response MUST be in Korean only.
        - Do NOT output English words, translations, or explanations.
        - If you output any English at all, even a single word, the answer is invalid.
        - ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        - Focus on psychological insights related to the drawing characteristics.
    """
    
    logger.info(f"\nğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} characters")

    result = generate_with_qwen(prompt)
    
    logger.info(f"âœ… [INTERPRET_SINGLE] í•´ì„ ì™„ë£Œ")
    logger.info(f"ìƒì„±ëœ í•´ì„: {result}")
    logger.info("=" * 80)
    return {"interpretation": result}

# ----------------------------- #
# 4) GPT-4o-minië¡œ ì¶”ê°€ ì§ˆë¬¸ ìƒì„±
# ----------------------------- #
from openai import OpenAI
client = OpenAI()

class QuestionReq(BaseModel):
    conversation: list

@app.post("/questions")
def questions(req: QuestionReq):
    logger.info("=" * 80)
    logger.info("â“ [QUESTIONS] ì¶”ê°€ ì§ˆë¬¸ ìƒì„± ì‹œì‘")
    logger.info(f"ëŒ€í™” ê¸°ë¡ ìˆ˜: {len(req.conversation)}")
    
    for idx, msg in enumerate(req.conversation[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ ë¡œê¹…
        logger.info(f"  ë©”ì‹œì§€ {idx}: {msg.get('role')} - {msg.get('content')[:100]}...")
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=req.conversation
    )
    
    question = response.choices[0].message.content
    logger.info(f"âœ… [QUESTIONS] ìƒì„±ëœ ì§ˆë¬¸: {question}")
    logger.info("=" * 80)
    return {"question": question}

# ----------------------------- #
# 5) ìµœì¢… í•´ì„ (Qwen + LoRA)
# ----------------------------- #
class InterpretFinal(BaseModel):
    single_results: dict
    conversation: list

@app.post("/interpret_final")
def interpret_final(req: InterpretFinal):
    logger.info("=" * 80)
    logger.info("ğŸ¯ [INTERPRET_FINAL] ìµœì¢… í•´ì„ ìƒì„± ì‹œì‘")
    logger.info(f"ì§‘ í•´ì„: {req.single_results.get('house', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ë‚˜ë¬´ í•´ì„: {req.single_results.get('tree', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ì‚¬ëŒ í•´ì„: {req.single_results.get('person', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ëŒ€í™” ê¸°ë¡ ìˆ˜: {len(req.conversation)}")
    
    prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ì§‘ í•´ì„:
{req.single_results.get('house','')}

ë‚˜ë¬´ í•´ì„:
{req.single_results.get('tree','')}

ì‚¬ëŒ í•´ì„:
{req.single_results.get('person','')}

ì‚¬ìš©ìì™€ ë‚˜ëˆˆ ëŒ€í™”:
{req.conversation}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•œ ìµœì¢… HTP í•´ì„ì„ 5ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”. ragì— í¬í•¨ëœ ì„¤ëª… ë˜í•œ ì˜ì–´ê°€ ìˆì„ê²½ìš° í•œê¸€ë¡œ ë²ˆì—­ í›„ ì‘ì„±í•˜ì„¸ìš”.
    """
    
    logger.info(f"ğŸ“ ìµœì¢… í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} characters")
    
    result = generate_with_qwen(prompt)
    
    logger.info(f"âœ… [INTERPRET_FINAL] ìµœì¢… í•´ì„ ì™„ë£Œ")
    logger.info(f"ìƒì„±ëœ ìµœì¢… í•´ì„ (ì²˜ìŒ 200ì): {result[:200]}...")
    logger.info("=" * 80)
    return {"final": result}
